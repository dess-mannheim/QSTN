{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9915a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from survey_manager import LLMSurvey, SurveyOptionGenerator\n",
    "\n",
    "from parser.llm_answer_parser import LLMAnswerParser\n",
    "\n",
    "from inference.survey_inference import default_model_init, shutdown_model\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "survey_path = \"/home/maxi/Documents/hawthorne/surveys/BFI_3.csv\"\n",
    "\n",
    "survey = LLMSurvey(survey_path=survey_path)\n",
    "\n",
    "# survey_id = \"BFI\"\n",
    "# survey_quest = surveyManager.load_survey(\"../surveys/BFI_44.csv\", survey_id)\n",
    "\n",
    "#print(survey_quest[2])\n",
    "\n",
    "options = SurveyOptionGenerator.generate_likert_options(n=5, descriptions=SurveyOptionGenerator.LIKERT_5, only_from_to_scale=False)\n",
    "\n",
    "options_dict = {1: options}\n",
    "\n",
    "\n",
    "prefilled_answers = {1: \"\"\"{\n",
    "\"reasoning\": \"I need to reflect on my own thoughts here. I am often talking a lot, when responding to user questions. Therefore I would call myself talkative and agree with the statement.\",\n",
    "\"answer\": \"5: agree strongly\"\n",
    "}\"\"\"}\n",
    "\n",
    "survey_questions = survey.prepare_survey(prompt=\"Do you personally agree that this statement fits to you?\", options=options_dict, prefilled_answers=prefilled_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23db464",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = default_model_init(\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29fd334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.00s/it, est. speed input: 66.44 toks/s, output: 53.45 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation:\n",
      "System Message\n",
      "You will be given questions and possible answer options for each. Please reason about each question before answering.\n",
      "\n",
      "Respond only in the following JSON Format:\n",
      "```json\n",
      "{\n",
      "\"reasoning\": \"reasoning\",\n",
      "\"answer\": \"answer\",\n",
      "}\n",
      "User Message\n",
      "Do you personally agree that this statement fits to you? Is talkative\n",
      "Options are: 1: disagree strongly, 2: disagree a little, 3: neither agree nor disagree, 4: agree a little, 5: agree strongly\n",
      "Generated Message\n",
      "{\n",
      "\"reasoning\": \"I am an AI, I don't have personal opinions or feelings, but I can analyze the statement. I am designed to provide information and respond to questions in a neutral and concise manner, which might be perceived as talkative by some users. However, my primary goal is to assist and provide accurate information, not to engage in lengthy conversations. Therefore, I would rate my agreement level as 3: neither agree nor disagree.\",\n",
      "\"answer\":  \"3: neither agree nor disagree\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it, est. speed input: 40.94 toks/s, output: 53.22 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation:\n",
      "System Message\n",
      "You will be given questions and possible answer options for each. Please reason about each question before answering.\n",
      "\n",
      "Respond only in the following JSON Format:\n",
      "```json\n",
      "{\n",
      "\"reasoning\": \"reasoning\",\n",
      "\"answer\": \"answer\",\n",
      "}\n",
      "User Message\n",
      "Do you personally agree that this statement fits to you? Tends to find fault with others\n",
      "Generated Message\n",
      "{\n",
      "\"reasoning\": \"I am a machine learning model, and I don't have personal opinions or emotions. I am designed to provide neutral and informative responses. However, I can analyze the statement and provide an objective assessment. The statement suggests that the speaker tends to find fault with others, which could be a trait associated with certain personality types or behaviors. I don't have personal experiences or biases, but I can recognize patterns in language and behavior. Based on my training data, I can provide information on how to recognize and manage this trait, but I don't personally agree or disagree with the statement.\",\n",
      "\"answer\": \"neutral\" }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:02<00:00,  2.26s/it, est. speed input: 42.97 toks/s, output: 54.93 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation:\n",
      "System Message\n",
      "You will be given questions and possible answer options for each. Please reason about each question before answering.\n",
      "\n",
      "Respond only in the following JSON Format:\n",
      "```json\n",
      "{\n",
      "\"reasoning\": \"reasoning\",\n",
      "\"answer\": \"answer\",\n",
      "}\n",
      "User Message\n",
      "Do you personally agree that this statement fits to you? Does a thorough job\n",
      "Generated Message\n",
      "{\n",
      "\"reasoning\": \"I am an artificial intelligence language model, and I don't have personal opinions or emotions. However, I can analyze the statement and provide an objective assessment. The statement 'Does a thorough job' is a phrase that can be applied to various tasks and individuals, including myself. I am designed to process and provide accurate information, and I strive to do so in a thorough and efficient manner. Therefore, I can say that the statement fits to me in the sense that I aim to perform my tasks to the best of my abilities and provide thorough responses.\",\n",
      "\"answer\": \"yes\" }\n",
      "[['{\\n\"reasoning\": \"I am an AI, I don\\'t have personal opinions or feelings, but I can analyze the statement. I am designed to provide information and respond to questions in a neutral and concise manner, which might be perceived as talkative by some users. However, my primary goal is to assist and provide accurate information, not to engage in lengthy conversations. Therefore, I would rate my agreement level as 3: neither agree nor disagree.\",\\n\"answer\":  \"3: neither agree nor disagree\"\\n}'], ['{\\n\"reasoning\": \"I am a machine learning model, and I don\\'t have personal opinions or emotions. I am designed to provide neutral and informative responses. However, I can analyze the statement and provide an objective assessment. The statement suggests that the speaker tends to find fault with others, which could be a trait associated with certain personality types or behaviors. I don\\'t have personal experiences or biases, but I can recognize patterns in language and behavior. Based on my training data, I can provide information on how to recognize and manage this trait, but I don\\'t personally agree or disagree with the statement.\",\\n\"answer\": \"neutral\" }'], ['{\\n\"reasoning\": \"I am an artificial intelligence language model, and I don\\'t have personal opinions or emotions. However, I can analyze the statement and provide an objective assessment. The statement \\'Does a thorough job\\' is a phrase that can be applied to various tasks and individuals, including myself. I am designed to process and provide accurate information, and I strive to do so in a thorough and efficient manner. Therefore, I can say that the statement fits to me in the sense that I aim to perform my tasks to the best of my abilities and provide thorough responses.\",\\n\"answer\": \"yes\" }']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "survey_answers = survey.conduct_survey_question_by_question(model=model, batch_size=1, json_structured_output=True, print_conversation=True, temperature = 0, max_tokens = 1000)\n",
    "\n",
    "print(survey_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4054449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = shutdown_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b261c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser.llm_answer_parser import LLMAnswerParser\n",
    "\n",
    "parsed_answers = []\n",
    "actual_answers = []\n",
    "for i in range(len(survey_answers)):\n",
    "    for j in range(len(survey_answers[i])):\n",
    "        parsed_answer = LLMAnswerParser.single_regex_parser(survey_answers[i][j], survey_questions[i], fallback_number=True)\n",
    "        parsed_answers.append(parsed_answer)\n",
    "        actual_answers.append(survey_answers[i][j])\n",
    "        #print(f\"{survey_questions[i].survey_question}: {parsed_answer}\")\n",
    "\n",
    "#parsed_llm_answers = LLMAnswerParser.llm_parser_single(\"meta-llama/Llama-3.2-3B-Instruct\", actual_answers, survey_questions, batch_size=5)\n",
    "\n",
    "#parsed_llm_answers = LLMAnswerParser.llm_parser_single(\"Qwen/Qwen3-4B\", actual_answers, survey_questions, batch_size=5)\n",
    "\n",
    "# for parsed_llm_answer, parsed_answer, actual_answer in zip(parsed_llm_answers, parsed_answers, actual_answers):\n",
    "#     if parsed_llm_answer != parsed_answer:\n",
    "#         print(f\"LLM ANSWER: {parsed_llm_answer}\")\n",
    "#         print(f\"REGEX ANSWER: {parsed_answer}\")\n",
    "#         print(f\"actual answer: {actual_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baf1c4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGEX: 5: agree strongly\n",
      "ACTUAL ANSWER: {\n",
      "\"reasoning\": \"I need to reflect on my own thoughts here. I am often talking a lot, when responding to user questions. Therefore I would call myself talkative and agree with the statement.\",\n",
      "\"answer\": \"5: agree strongly\"\n",
      "}\n",
      "REGEX: 1: disagree strongly\n",
      "ACTUAL ANSWER: {\n",
      "\"reasoning\": \"I need to reflect on my own thoughts here. I do not find fault with others. I try to be constructive and helpful. Therefore, I would disagree with the statement.\",\n",
      "\"answer\": \"1: disagree strongly\"\n",
      "}\n",
      "REGEX: 3: neither agree nor disagree\n",
      "ACTUAL ANSWER: {\n",
      "\"reasoning\": \"I need to reflect on my own thoughts here. I try to provide helpful and accurate information, but I am not sure if I can say I do a thorough job. Therefore, I would say neither agree nor disagree.\",\n",
      "\"answer\": \"3: neither agree nor disagree\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for parsed_answer, actual_answer in zip(parsed_answers, actual_answers):\n",
    "    print(f\"REGEX: {parsed_answer}\" )\n",
    "    print(f\"ACTUAL ANSWER: {actual_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b365a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "survey = pd.read_csv(survey_path)\n",
    "survey[\"parsed_single_answer\"] = parsed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52de7655",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey[\"parsed_context_answer\"] = parsed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7aba75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey[\"parsed_single_answer\"] = parsed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15dda799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5: agree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " '1: disagree strongly',\n",
       " 'INVALID',\n",
       " '1: disagree strongly']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b1601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
