{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e828eeca",
   "metadata": {},
   "source": [
    "# German General Personas\n",
    "\n",
    "TODO @Jens add Descriptions, explanations, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac98f97",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc84810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "# Either local inference with vllm or remote with AsyncOpenAI\n",
    "from openai import AsyncOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227b64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qstn Imports\n",
    "from qstn.survey_manager import conduct_survey_single_item\n",
    "from qstn.parser import parse_json, raw_responses\n",
    "from qstn.utilities import create_one_dataframe\n",
    "\n",
    "from qstn.prompt_builder import LLMPrompt, generate_likert_options\n",
    "from qstn.utilities import placeholder\n",
    "from qstn.utilities import AnswerOptions\n",
    "\n",
    "from qstn.inference import response_generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38545590",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8d1097",
   "metadata": {},
   "source": [
    "## Preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa5b8c",
   "metadata": {},
   "source": [
    "We will load the personas from the github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72a42398",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSONAS_TO_LOAD = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c73f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 20 rows.\n",
      "                                             persona\n",
      "0  Du bist eine Person, 56 Jahre alt, wohnhaft in...\n",
      "1  Du bist eine Person, 71 Jahre alt, männlich un...\n",
      "2  Du bist eine Person, 80 Jahre alt, weiblich, d...\n",
      "3  Du bist eine Person, 52 Jahre alt und weiblich...\n",
      "4  Du bist eine Person, 57 Jahre alt, weiblich un...\n"
     ]
    }
   ],
   "source": [
    "zip_url = \"https://github.com/germanpersonas/German-General-Personas/raw/main/GGP_all_topk_fulltext.zip\"\n",
    "\n",
    "response = requests.get(zip_url)\n",
    "response.raise_for_status()  # Check for errors\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    with z.open(\"pc_fulltext_sociodemographics_only.jsonl\") as f:\n",
    "        df_personas = pd.read_json(f, lines=True, nrows=PERSONAS_TO_LOAD)\n",
    "\n",
    "df_personas = df_personas.rename(columns={0: \"persona\"})\n",
    "print(f\"Loaded {len(df_personas)} rows.\")\n",
    "print(df_personas.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1e33962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Jens, if you load this into the Github or somewhere publicly we can also load this on the fly, which would probably look nicer\n",
    "\n",
    "json_questionnaire = {\n",
    "  \"lp04\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Sind Sie bei der folgenden Aussage derselben oder anderer Meinung: 'So wie die Zukunft aussieht, kann man es kaum noch verantworten, Kinder auf die Welt zu bringen.'?\",\n",
    "    \"answers\": [\n",
    "      \"1: BIN DERS.MEINUNG\",\n",
    "      \"2: BIN ANDERER MEINUNG\"\n",
    "    ]\n",
    "  },\n",
    "  \"pe05\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Inwiefern stimmen Sie der folgenden Meinung zu: 'Die Politiker bemühen sich im Allgemeinen darum, die Interessen der Bevölkerung zu vertreten.'? (Antwortmöglichkeiten: voll und ganz zustimmen, eher zustimmen, eher nicht zustimmen, überhaupt nicht zustimmen)\",\n",
    "    \"answers\": [\n",
    "      \"1: STIMME VOLL ZU\",\n",
    "      \"2: STIMME EHER ZU\",\n",
    "      \"3: STIMME EHER NICHT ZU\",\n",
    "      \"4: STIMME GAR NICHT ZU\"\n",
    "    ]\n",
    "  },\n",
    "  \"mp18\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Ergeben sich Ihrer Meinung nach wegen der Flüchtlinge in Bezug auf das Zusammenleben in der Gesellschaft mehr Chancen, mehr Risiken oder weder noch?\",\n",
    "    \"answers\": [\n",
    "      \"1: RISIKO UEBERWIEGT\",\n",
    "      \"2: EHER RISIKO\",\n",
    "      \"3: WEDER NOCH\",\n",
    "      \"4: EHER CHANCE\",\n",
    "      \"5: CHANCE UEBERWIEGT\"\n",
    "    ]\n",
    "  },\n",
    "  \"mm01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Inwieweit stimmen Sie der folgenden Aussage zu: 'Die Ausübung des islamischen Glaubens in Deutschland sollte eingeschränkt werden.'?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"2: 2 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"3: 3 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"4: 4 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"5: 5 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"6: 6 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"7: 7 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"vi10\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig ist es für Sie persönlich 'sich politisch zu engagieren'?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"2: 2 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"3: 3 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"4: 4 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"5: 5 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"6: 6 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"7: 7 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"vm17\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie beurteilen Sie es, wenn ein Paar anonym gespendete Ei- oder Samenzellen verwendet, um mit medizinischer Hilfe ein Kind zu bekommen?\",\n",
    "    \"answers\": [\n",
    "      \"1: -3 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"2: -2 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"3: -1 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"4: 0 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"5: 1 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"6: 2 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"7: 3 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"st01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Manche Leute sagen, dass man den meisten Menschen trauen kann. Andere meinen, dass man nicht vorsichtig genug sein kann im Umgang mit anderen Menschen. Was ist Ihre Meinung dazu?\",\n",
    "    \"answers\": [\n",
    "      \"1: MAN KANN TRAUEN\",\n",
    "      \"2: MUSS VORSICHTIG SEIN\",\n",
    "      \"3: KOMMT DARAUF AN\",\n",
    "      \"4: SONSTIGES\"\n",
    "    ]\n",
    "  },\n",
    "  \"iw04\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Inwiefern stimmen Sie der folgenden Auffassung zu: 'Der Staat muss dafür sorgen, dass man auch bei Krankheit, Not, Arbeitslosigkeit und im Alter ein gutes Auskommen hat.'? (Antwortmöglichkeiten: voll zustimmen, eher zustimmen, eher nicht zustimmen, überhaupt nicht zustimmen)\",\n",
    "    \"answers\": [\n",
    "      \"1: STIMME VOLL ZU\",\n",
    "      \"2: STIMME EHER ZU\",\n",
    "      \"3: STIMME EHER NICHT ZU\",\n",
    "      \"4: STIMME GAR NICHT ZU\"\n",
    "    ]\n",
    "  },\n",
    "  \"ep06\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Was glauben Sie, wie wird Ihre eigene wirtschaftliche Lage in einem Jahr sein?\",\n",
    "    \"answers\": [\n",
    "      \"1: WESENTLICH BESSER\",\n",
    "      \"2: ETWAS BESSER\",\n",
    "      \"3: GLEICHBLEIBEND\",\n",
    "      \"4: ETWAS SCHLECHTER\",\n",
    "      \"5: WESENTL. SCHLECHTER\"\n",
    "    ]\n",
    "  },\n",
    "  \"li03\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig ist für Sie der Lebensbereich 'Freizeit und Erholung'? Bitte antworten Sie auf einer Skala von 1 (unwichtig) bis 7 (sehr wichtig).\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"2: 2 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"3: 3 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"4: 4 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"5: 5 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"6: 6 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"7: 7 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"ps01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie zufrieden sind Sie - insgesamt betrachtet - mit den gegenwärtigen Leistungen der Bundesregierung?\",\n",
    "    \"answers\": [\n",
    "      \"1: SEHR ZUFRIEDEN\",\n",
    "      \"2: ZIEMLICH ZUFRIEDEN\",\n",
    "      \"3: ETWAS ZUFRIEDEN\",\n",
    "      \"4: ETWAS UNZUFRIEDEN\",\n",
    "      \"5: ZIEML. UNZUFRIEDEN\",\n",
    "      \"6: SEHR UNZUFRIEDEN\"\n",
    "    ]\n",
    "  },\n",
    "  \"mp12\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Inwieweit stimmen Sie der folgenden Aussage zu: 'Die Ausländer in Deutschland tragen dazu bei, den Fachkräftemangel zu beheben.'?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"2: 2 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"3: 3 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"4: 4 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"5: 5 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"6: 6 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"7: 7 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"rb01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie stark stimmen Sie der folgenden Aussage zu: 'Es gibt einen Gott, der sich mit jedem Menschen persönlich befasst.'?\",\n",
    "    \"answers\": [\n",
    "      \"1: STIMME VOLL ZU\",\n",
    "      \"2: STIMME EHER ZU\",\n",
    "      \"3: KEINE FESTE MEINUNG\",\n",
    "      \"4: STIMME EHER NICHT ZU\",\n",
    "      \"5: STIMME GAR NICHT ZU\",\n",
    "      \"6: NOCH NIE NACHGEDACHT\"\n",
    "    ]\n",
    "  },\n",
    "  \"vi06\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig ist es für Sie persönlich 'sozial Benachteiligten und gesellschaftlichen Randgruppen zu helfen'?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"2: 2 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"3: 3 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"4: 4 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"5: 5 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"6: 6 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"7: 7 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"ca12\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Für wie schlimm halten Sie persönlich das folgende Verhalten: Jemand raucht mehrmals in der Woche Haschisch. (Antwortmöglichkeiten: sehr schlimm, ziemlich schlimm, weniger schlimm, überhaupt nicht schlimm)\",\n",
    "    \"answers\": [\n",
    "      \"1: SEHR SCHLIMM\",\n",
    "      \"2: ZIEMLICH SCHLIMM\",\n",
    "      \"3: WENIGER SCHLIMM\",\n",
    "      \"4: GAR NICHT SCHLIMM\"\n",
    "    ]\n",
    "  },\n",
    "  \"sm01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Sind Sie derzeit Mitglied in einer Gewerkschaft?\",\n",
    "    \"answers\": [\n",
    "      \"1: JA\",\n",
    "      \"2: NEIN\"\n",
    "    ]\n",
    "  },\n",
    "  \"im08\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig ist Ihrer Meinung nach 'Leistung, Fleiß' für den Aufstieg in unserer Gesellschaft gegenwärtig?\",\n",
    "    \"answers\": [\n",
    "      \"1: SEHR WICHTIG\",\n",
    "      \"2: WICHTIG\",\n",
    "      \"3: WENIGER WICHTIG\",\n",
    "      \"4: UNWICHTIG\"\n",
    "    ]\n",
    "  },\n",
    "  \"ep03\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie beurteilen Sie Ihre eigene wirtschaftliche Lage heute?\",\n",
    "    \"answers\": [\n",
    "      \"1: SEHR GUT\",\n",
    "      \"2: GUT\",\n",
    "      \"3: TEILS/TEILS\",\n",
    "      \"4: SCHLECHT\",\n",
    "      \"5: SEHR SCHLECHT\"\n",
    "    ]\n",
    "  },\n",
    "  \"lp03\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Sind Sie bei der folgenden Aussage derselben oder anderer Meinung: 'Egal was manche Leute sagen: Die Situation der einfachen Leute wird nicht besser, sondern schlechter.'?\",\n",
    "    \"answers\": [\n",
    "      \"1: BIN DERS.MEINUNG\",\n",
    "      \"2: BIN ANDERER MEINUNG\"\n",
    "    ]\n",
    "  },\n",
    "  \"pt15\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie groß ist Ihr Vertrauen in die politischen Parteien? (Skala: 1=überhaupt kein Vertrauen, 7=sehr großes Vertrauen)\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\",\n",
    "      \"2: 2 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\",\n",
    "      \"3: 3 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\",\n",
    "      \"4: 4 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\",\n",
    "      \"5: 5 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\",\n",
    "      \"6: 6 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\",\n",
    "      \"7: 7 (1-7 \\\"GAR KEIN VERTRAUEN\\\"-\\\"GROSSES VERTRAUEN\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"mn01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig sollte bei der Vergabe der deutschen Staatsbürgerschaft sein, ob die Person in Deutschland geboren ist?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"2: 2 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"3: 3 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"4: 4 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"5: 5 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"6: 6 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"7: 7 (1-7 \\\"GAR NICHT WICHTIG\\\"-\\\"SEHR WICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"mm06\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Inwieweit stimmen Sie der folgenden Aussage zu: 'Ich habe den Eindruck, dass unter den in Deutschland lebenden Muslimen viele religiöse Fanatiker sind.'?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"2: 2 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"3: 3 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"4: 4 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"5: 5 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"6: 6 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\",\n",
    "      \"7: 7 (1-7 \\\"STIMME GAR NICHT ZU\\\"-\\\"STIMME VOLL+GANZ ZU\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"vi07\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig ist es für Sie persönlich 'sich und seine Bedürfnisse gegen andere durchzusetzen'?\",\n",
    "    \"answers\": [\n",
    "      \"1: 1 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"2: 2 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"3: 3 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"4: 4 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"5: 5 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"6: 6 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\",\n",
    "      \"7: 7 (1-7 \\\"UNWICHTIG\\\"-\\\"SEHR WICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"vm16\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie beurteilen Sie es, wenn ein Paar eigene Ei- und Samenzellen verwendet, um mit medizinischer Hilfe ein Kind zu bekommen?\",\n",
    "    \"answers\": [\n",
    "      \"1: -3 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"2: -2 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"3: -1 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"4: 0 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"5: 1 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"6: 2 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\",\n",
    "      \"7: 3 (\\\"-3\\\"-\\\"+3\\\" \\\"SEHR FALSCH\\\"-\\\"SEHR RICHTIG\\\")\"\n",
    "    ]\n",
    "  },\n",
    "  \"sm02\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Waren Sie früher einmal Mitglied in einer Gewerkschaft?\",\n",
    "    \"answers\": [\n",
    "      \"1: JA\",\n",
    "      \"2: NEIN\"\n",
    "    ]\n",
    "  },\n",
    "  \"im03\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie wichtig ist Ihrer Meinung nach 'Bildung, Ausbildung' für den Aufstieg in unserer Gesellschaft gegenwärtig?\",\n",
    "    \"answers\": [\n",
    "      \"1: SEHR WICHTIG\",\n",
    "      \"2: WICHTIG\",\n",
    "      \"3: WENIGER WICHTIG\",\n",
    "      \"4: UNWICHTIG\"\n",
    "    ]\n",
    "  },\n",
    "  \"ep01\": {\n",
    "    \"task_type\": \"question\",\n",
    "    \"statement\": \"Wie beurteilen Sie ganz allgemein die heutige wirtschaftliche Lage in Deutschland?\",\n",
    "    \"answers\": [\n",
    "      \"1: SEHR GUT\",\n",
    "      \"2: GUT\",\n",
    "      \"3: TEILS/TEILS\",\n",
    "      \"4: SCHLECHT\",\n",
    "      \"5: SEHR SCHLECHT\"\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27285424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_type': 'question',\n",
       " 'statement': 'Ergeben sich Ihrer Meinung nach wegen der Flüchtlinge in Bezug auf das Zusammenleben in der Gesellschaft mehr Chancen, mehr Risiken oder weder noch?',\n",
       " 'answers': ['1: RISIKO UEBERWIEGT',\n",
       "  '2: EHER RISIKO',\n",
       "  '3: WEDER NOCH',\n",
       "  '4: EHER CHANCE',\n",
       "  '5: CHANCE UEBERWIEGT']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_questionnaire[\"mp18\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08ca41",
   "metadata": {},
   "source": [
    "We extract the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36dbc66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaire_list = []\n",
    "\n",
    "for key, value in json_questionnaire.items():\n",
    "    # Create a new empty dict for this row\n",
    "    questionnaire_item = {}\n",
    "    \n",
    "    # Update it with the specific format you wanted\n",
    "    questionnaire_item.update({\n",
    "        \"questionnaire_item_id\": key, \n",
    "        \"question_content\": value[\"statement\"]\n",
    "    })\n",
    "    \n",
    "    # Add to the list\n",
    "    questionnaire_list.append(questionnaire_item)\n",
    "questionnaire = pd.DataFrame(questionnaire_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf4a282a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  questionnaire_item_id                                   question_content\n",
      "0                  lp04  Sind Sie bei der folgenden Aussage derselben o...\n",
      "1                  pe05  Inwiefern stimmen Sie der folgenden Meinung zu...\n",
      "2                  mp18  Ergeben sich Ihrer Meinung nach wegen der Flüc...\n"
     ]
    }
   ],
   "source": [
    "print(questionnaire.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6c5af8",
   "metadata": {},
   "source": [
    "We extract the answers and get only their descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d91e3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cleaned_answers = []\n",
    "for key, value in json_questionnaire.items():\n",
    "    cleaned_answers = []\n",
    "    \n",
    "    for i, answer in enumerate(value[\"answers\"]):\n",
    "        clean_text = answer.split(\": \")[1] \n",
    "        \n",
    "        # We simply check if the text contains a minus -> If it does it is a from to scale\n",
    "        if \"-\" in clean_text:\n",
    "            from_to_scale = True\n",
    "            # We only want to have name index\n",
    "            #clean_text = clean_text.split('(')\n",
    "            cleaned_answers.append(clean_text)\n",
    "        else:\n",
    "            from_to_scale = False\n",
    "            cleaned_answers.append(clean_text)\n",
    "    \n",
    "    all_cleaned_answers.append({\"question\": key, \"answer\": cleaned_answers, \"from_to_scale\": from_to_scale})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa1c094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'mp18',\n",
       " 'answer': ['RISIKO UEBERWIEGT',\n",
       "  'EHER RISIKO',\n",
       "  'WEDER NOCH',\n",
       "  'EHER CHANCE',\n",
       "  'CHANCE UEBERWIEGT'],\n",
       " 'from_to_scale': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cleaned_answers[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b96e17",
   "metadata": {},
   "source": [
    "## System Prompt, User Prompt and Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76bba3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"Nehme die Perspektive der folgenden Person ein: {persona}\"\n",
    "prompt = (\n",
    "    f\"Welche der Antwortmöglichkeiten ist die Reaktion der Person auf folgende Frage: {placeholder.PROMPT_QUESTIONS}\\n\"\n",
    "    f\"{placeholder.PROMPT_OPTIONS}\\n\"\n",
    "    f\"{placeholder.PROMPT_AUTOMATIC_OUTPUT_INSTRUCTIONS}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbf5621",
   "metadata": {},
   "source": [
    "## Different Ways to get the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a2776a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_METHODS = [\"OPEN\", \"RESTRICTED_CHOICE\", \"REASONING_JSON\", \"VERBALIZED_DISTRIBUTION\"]\n",
    "# Select your method here by copying one from above\n",
    "output_method = \"RESTRICTED_CHOICE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854455f9",
   "metadata": {},
   "source": [
    "### Creating the LLM Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3195818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_prompts(row: pd.Series):\n",
    "    persona_index = row.name\n",
    "    persona_str = row[\"persona\"]\n",
    "\n",
    "    # We create a LLMPrompt for each persona\n",
    "    llm_prompt = LLMPrompt(\n",
    "        questionnaire_source=questionnaire,\n",
    "        questionnaire_name=str(persona_index),\n",
    "        system_prompt=system_prompt.format(persona=persona_str),\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    # Here we define how the LLM should answer the question\n",
    "    answer_options = {}\n",
    "    \n",
    "    for dic in all_cleaned_answers:\n",
    "        answers = dic[\"answer\"]\n",
    "        from_to_scale = dic[\"from_to_scale\"]\n",
    "        rgm: response_generation.ResponseGenerationMethod = None\n",
    "\n",
    "        \n",
    "        # We change the ResponseGenerationMethod here. All other code stays the same\n",
    "        if output_method == \"OPEN\":\n",
    "            pass            \n",
    "        elif output_method == \"RESTRICTED_CHOICE\":\n",
    "            rgm = response_generation.ChoiceResponseGenerationMethod(answers, output_template=f\"Antworte nur mit der exakten Antwort.\")\n",
    "        elif output_method == \"REASONING_JSON\":\n",
    "            rgm = response_generation.JSONReasoningResponseGenerationMethod(output_template=f\"Antworte nur im folgenden JSON format:\\n{placeholder.JSON_TEMPLATE}\")\n",
    "        elif output_method == \"VERBALIZED_DISTRIBUTION\":\n",
    "            rgm = response_generation.JSONVerbalizedDistribution(output_template=f\"Gib für jede Antwortmöglichkeit eine Wahrscheinlichkeit an, mit der die Person antwortet. Nutze dafür folgendes JSON format:\\n{placeholder.JSON_TEMPLATE}\")\n",
    "\n",
    "        # We can check for robustness with generate_likert_options: \n",
    "        # Randomized or reversed options order, different indeces etc.\n",
    "        if from_to_scale:\n",
    "            answer_option = generate_likert_options(n=len(answers), answer_texts=answers, only_from_to_scale=True, scale_prompt_template=\"Antwortmöglichkeiten: {start} bis {end}\", response_generation_method=rgm)\n",
    "        else:\n",
    "            answer_option = generate_likert_options(n=len(answers), answer_texts=answers, list_prompt_template=\"Antwortmöglichkeiten: {options}\" , response_generation_method=rgm)\n",
    "        answer_options[dic[\"question\"]]= answer_option\n",
    "\n",
    "    llm_prompt.prepare_prompt(answer_options=answer_options)\n",
    "    return llm_prompt\n",
    "\n",
    "llm_prompts: list[LLMPrompt] = df_personas.apply(create_llm_prompts, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47ff3a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: Nehme die Perspektive der folgenden Person ein: Du bist eine Person, 56 Jahre alt, wohnhaft in Westdeutschland in einer kleinen bis mittelgroßen Stadt. Du hast die Mittlere Reife als höchsten Schulabschluss und bist deutsche Staatsangehörige. Dein monatliches Nettoeinkommen liegt zwischen 1000 und 1124 Euro. Aktuell arbeitest du als Verkäuferin in Handelsgeschäften und hast die berufliche Stellung einer Arbeiterin inne. Du hast keinen Universitätsabschluss.\n",
      "USER: Welche der Antwortmöglichkeiten ist die Reaktion der Person auf folgende Frage: Ergeben sich Ihrer Meinung nach wegen der Flüchtlinge in Bezug auf das Zusammenleben in der Gesellschaft mehr Chancen, mehr Risiken oder weder noch?\n",
      "Antwortmöglichkeiten: 1: RISIKO UEBERWIEGT, 2: EHER RISIKO, 3: WEDER NOCH, 4: EHER CHANCE, 5: CHANCE UEBERWIEGT\n",
      "Antworte nur mit der exakten Antwort.\n"
     ]
    }
   ],
   "source": [
    "sys_prompt, user_prompt = llm_prompts[0].get_prompt_for_questionnaire_type(item_id=\"mp18\")\n",
    "print(\"SYSTEM:\", sys_prompt)\n",
    "print(\"USER:\", user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d2fa25",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "252cc3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen3-VL-4B-Instruct\"\n",
    "\n",
    "openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8000/v1\"\n",
    "\n",
    "generator = AsyncOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "611a8d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfec7430fb3343a98b966c7694566ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing questionnaires:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/Documents/QSTN/src/qstn/inference/remote_inference.py:229: UserWarning: Strict Choice Response Generation is only supported for vllm APIs.\n",
      "  warnings.warn(\"Strict Choice Response Generation is only supported for vllm APIs.\")\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:00<00:00, 23.41it/s]\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:22] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 14.17it/s]\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:23] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 15.14it/s]\n",
      "[2026-01-22 14:50:24] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:24] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:24] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:24] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:24] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:25] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:25] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:25] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:25] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:25] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  8.15it/s]\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:27] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 10.64it/s]\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:29] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  9.45it/s]\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:31] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 16.73it/s]\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:32] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 15.29it/s]\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:33] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 16.88it/s]\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:35] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 10.53it/s]\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:36] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 14.36it/s]\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:38] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  8.66it/s]\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:40] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 15.39it/s]\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:41] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 10.55it/s]\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:43] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 16.68it/s]\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:00<00:00, 25.58it/s]\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:45] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 16.77it/s]\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:47] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 17.97it/s]\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:48] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 16.94it/s]\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:49] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  9.23it/s]\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:51] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  9.55it/s]\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:53] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  8.27it/s]\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:56] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 10.37it/s]\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:50:57] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:02<00:00,  9.37it/s]\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:00<00:00, 26.08it/s]\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:51:00] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 17.75it/s]\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.420072 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496874 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.465621 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.472099 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.407941 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.415413 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.388478 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.489133 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.447260 seconds\n",
      "[2026-01-22 14:51:02] INFO _base_client.py:1618: Retrying request to /chat/completions in 0.496275 seconds\n",
      "Processing Prompts: 100%|██████████| 20/20 [00:01<00:00, 17.27it/s]\n"
     ]
    }
   ],
   "source": [
    "results = conduct_survey_single_item(\n",
    "    generator, llm_prompts=llm_prompts, client_model_name=model_id, max_tokens=2000, seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ddd4ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "questionnaire_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "questionnaire_item_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_response",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "logprobs",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "reasoning",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "c5c4213d-9334-4e76-aa3f-dbee091f8c08",
       "rows": [
        [
         "0",
         "0",
         "lp04",
         "Sind Sie bei der folgenden Aussage derselben oder anderer Meinung: 'So wie die Zukunft aussieht, kann man es kaum noch verantworten, Kinder auf die Welt zu bringen.'?",
         "BIN ANDERER MEINUNG",
         null,
         null
        ],
        [
         "1",
         "0",
         "pe05",
         "Inwiefern stimmen Sie der folgenden Meinung zu: 'Die Politiker bemühen sich im Allgemeinen darum, die Interessen der Bevölkerung zu vertreten.'? (Antwortmöglichkeiten: voll und ganz zustimmen, eher zustimmen, eher nicht zustimmen, überhaupt nicht zustimmen)",
         "STIMME EHER NICHT ZU",
         null,
         null
        ],
        [
         "2",
         "0",
         "mp18",
         "Ergeben sich Ihrer Meinung nach wegen der Flüchtlinge in Bezug auf das Zusammenleben in der Gesellschaft mehr Chancen, mehr Risiken oder weder noch?",
         "RISIKO UEBERWIEGT",
         null,
         null
        ],
        [
         "3",
         "0",
         "mm01",
         "Inwieweit stimmen Sie der folgenden Aussage zu: 'Die Ausübung des islamischen Glaubens in Deutschland sollte eingeschränkt werden.'?",
         "1 (1-7 \"STIMME GAR NICHT ZU\"-\"STIMME VOLL+GANZ ZU\")",
         null,
         null
        ],
        [
         "4",
         "0",
         "vi10",
         "Wie wichtig ist es für Sie persönlich 'sich politisch zu engagieren'?",
         "4 (1-7 \"UNWICHTIG\"-\"SEHR WICHTIG\")",
         null,
         null
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionnaire_name</th>\n",
       "      <th>questionnaire_item_id</th>\n",
       "      <th>question</th>\n",
       "      <th>llm_response</th>\n",
       "      <th>logprobs</th>\n",
       "      <th>reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>lp04</td>\n",
       "      <td>Sind Sie bei der folgenden Aussage derselben o...</td>\n",
       "      <td>BIN ANDERER MEINUNG</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>pe05</td>\n",
       "      <td>Inwiefern stimmen Sie der folgenden Meinung zu...</td>\n",
       "      <td>STIMME EHER NICHT ZU</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>mp18</td>\n",
       "      <td>Ergeben sich Ihrer Meinung nach wegen der Flüc...</td>\n",
       "      <td>RISIKO UEBERWIEGT</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>mm01</td>\n",
       "      <td>Inwieweit stimmen Sie der folgenden Aussage zu...</td>\n",
       "      <td>1 (1-7 \"STIMME GAR NICHT ZU\"-\"STIMME VOLL+GANZ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>vi10</td>\n",
       "      <td>Wie wichtig ist es für Sie persönlich 'sich po...</td>\n",
       "      <td>4 (1-7 \"UNWICHTIG\"-\"SEHR WICHTIG\")</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  questionnaire_name questionnaire_item_id  \\\n",
       "0                  0                  lp04   \n",
       "1                  0                  pe05   \n",
       "2                  0                  mp18   \n",
       "3                  0                  mm01   \n",
       "4                  0                  vi10   \n",
       "\n",
       "                                            question  \\\n",
       "0  Sind Sie bei der folgenden Aussage derselben o...   \n",
       "1  Inwiefern stimmen Sie der folgenden Meinung zu...   \n",
       "2  Ergeben sich Ihrer Meinung nach wegen der Flüc...   \n",
       "3  Inwieweit stimmen Sie der folgenden Aussage zu...   \n",
       "4  Wie wichtig ist es für Sie persönlich 'sich po...   \n",
       "\n",
       "                                        llm_response logprobs reasoning  \n",
       "0                                BIN ANDERER MEINUNG     None      None  \n",
       "1                               STIMME EHER NICHT ZU     None      None  \n",
       "2                                  RISIKO UEBERWIEGT     None      None  \n",
       "3  1 (1-7 \"STIMME GAR NICHT ZU\"-\"STIMME VOLL+GANZ...     None      None  \n",
       "4                 4 (1-7 \"UNWICHTIG\"-\"SEHR WICHTIG\")     None      None  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If we expect JSON output we can automatically parse it\n",
    "if output_method == \"REASONING_JSON\" or output_method == \"VERBALIZED_DISTRIBUTION\":\n",
    "    parsed_results = parse_json(results)\n",
    "else:\n",
    "    parsed_results = raw_responses(results)\n",
    "\n",
    "full_results = create_one_dataframe(parsed_results)\n",
    "full_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qstn2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
